{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from minichess.concepts.concepts import in_check, random, threat_opp_queen, material_advantage, has_mate_threat, opponent_has_mate_threat, has_contested_open_file\n",
    "\n",
    "np.seterr(over=\"ignore\", invalid=\"raise\")\n",
    "\n",
    "# Your agent's name here\n",
    "model_name = \"mbappe\"\n",
    "# The epochs you want to sample from\n",
    "agents_to_sample = [1, 5, 10, 15, 20]\n",
    "# The name of the board-variant here\n",
    "full_name = \"5x4silverman\"\n",
    "dims = (5, 4)\n",
    "\n",
    "# This can be replaced by some other concept function\n",
    "CONCEPT_FUNC = material_advantage\n",
    "\n",
    "concept_name = material_advantage.__name__\n",
    "\n",
    "epochs_to_look_at = [1, 5, 10, 15, 20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\Rares\\AppData\\Local\\Temp\\tmpbp3ojglf\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\Rares\\AppData\\Local\\Temp\\tmpbp3ojglf\\assets\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\Rares\\AppData\\Local\\Temp\\tmpkiftvnlr\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\Rares\\AppData\\Local\\Temp\\tmpkiftvnlr\\assets\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\Rares\\AppData\\Local\\Temp\\tmp_susp_pq\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\Rares\\AppData\\Local\\Temp\\tmp_susp_pq\\assets\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\Rares\\AppData\\Local\\Temp\\tmpqlqmpcro\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\Rares\\AppData\\Local\\Temp\\tmpqlqmpcro\\assets\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\Rares\\AppData\\Local\\Temp\\tmp6wglxd2k\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\Rares\\AppData\\Local\\Temp\\tmp6wglxd2k\\assets\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from minichess.agents.lite_model import LiteModel\n",
    "from minichess.agents.predictor_convnet import PredictorConvNet\n",
    "\n",
    "def load_model(full_name, model_name, epoch):\n",
    "    keras_model = tf.keras.models.load_model(\"minichess/agents/checkpoints/{}/{}/{}\".format(full_name, model_name, epoch))\n",
    "    simple_model = PredictorConvNet(LiteModel.from_keras_model(keras_model))\n",
    "    del keras_model\n",
    "    return simple_model\n",
    "\n",
    "agents = [load_model(full_name, model_name, epoch) for epoch in agents_to_sample]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "from minichess.agents.lite_model import LiteModel\n",
    "from minichess.agents.predictor_convnet import PredictorConvNet\n",
    "from minichess.chess.fastchess import Chess\n",
    "from minichess.chess.fastchess_utils import piece_matrix_to_legal_moves, visualize_board\n",
    "from minichess.chess.move_utils import calculate_all_moves, index_to_move, move_to_index\n",
    "from minichess.rl.chess_helpers import get_initial_chess_object\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "def play_match(agents, full_name, dims, move_cap, all_moves, all_moves_inv, concept_function):\n",
    "    chess = get_initial_chess_object(full_name)\n",
    "    to_start = 1 if np.random.random() > 0.5 else 0\n",
    "    current = to_start\n",
    "    positive_cases = []\n",
    "    negative_cases = []\n",
    "    SAMPLING_RATIO = 0.2\n",
    "\n",
    "    while chess.game_result() is None:\n",
    "        if np.random.random() < SAMPLING_RATIO:\n",
    "            if concept_function(chess):\n",
    "                positive_cases.append(chess.agent_board_state())\n",
    "            else:\n",
    "                negative_cases.append(chess.agent_board_state())\n",
    "\n",
    "\n",
    "        agent_to_play = agents[current]\n",
    "        dist, value = agent_to_play.predict(chess.agent_board_state())\n",
    "\n",
    "        moves, proms = chess.legal_moves()\n",
    "        legal_moves = piece_matrix_to_legal_moves(moves, proms)\n",
    "        legal_moves_mask = np.zeros((dims[0], dims[1], all_moves_inv.shape[0]))\n",
    "        for move in legal_moves:\n",
    "            (i, j), (dx, dy), promotion = move\n",
    "            ind = move_to_index(all_moves, dx, dy, promotion, chess.turn)\n",
    "            legal_moves_mask[i, j, ind] = 1\n",
    "\n",
    "        move_dims = dist.shape\n",
    "\n",
    "        dist = (dist + 0.5 * np.random.uniform(size=dist.shape)) * legal_moves_mask.flatten()\n",
    "\n",
    "        dist /= dist.sum()\n",
    "        move_to_play = np.argmax(dist)\n",
    "\n",
    "        # move_to_play = np.random.choice(np.arange(dist.shape[0]), p=dist)\n",
    "        i, j, ind = np.unravel_index(move_to_play, (dims[0], dims[1], move_cap))\n",
    "        dx, dy, promotion = index_to_move(all_moves_inv, ind, chess.turn)\n",
    "        chess.make_move(i, j, dx, dy, promotion)\n",
    "        current = (current + 1) % 2\n",
    "    return positive_cases, negative_cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_moves, all_moves_inv = calculate_all_moves(dims)\n",
    "move_cap = all_moves_inv.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [23:05<00:00,  1.44it/s] \n",
      "100%|█████████▉| 1997/2000 [00:23<00:00, 75.14it/s] "
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "positive_cases = []\n",
    "negative_cases = []\n",
    "\n",
    "CASES_TO_COLLECT = 2000\n",
    "pbar = tqdm(total=CASES_TO_COLLECT)\n",
    "while len(positive_cases) < CASES_TO_COLLECT:\n",
    "    pos, neg = play_match([agents[0], agents[2]], full_name, dims, move_cap, all_moves, all_moves_inv, CONCEPT_FUNC)\n",
    "    positive_cases.extend(pos)\n",
    "    negative_cases.extend(neg)\n",
    "    pbar.update(len(pos))\n",
    "\n",
    "positive_cases = positive_cases[:CASES_TO_COLLECT]\n",
    "negative_cases = negative_cases[:CASES_TO_COLLECT]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_cases = np.array(positive_cases)\n",
    "negative_cases = np.array(negative_cases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positive_cases.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "negative_cases.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting outputs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 125/125 [00:01<00:00, 91.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merging outputs...\n",
      "Outputs merged.\n",
      "(4000, 980)\n",
      "Performing regression for layer 0\n",
      "Epoch 1/50\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 1.0825 - val_loss: 1.0506\n",
      "Epoch 2/50\n",
      "100/100 [==============================] - 0s 924us/step - loss: 1.0272 - val_loss: 1.0014\n",
      "Epoch 3/50\n",
      "100/100 [==============================] - 0s 924us/step - loss: 0.9789 - val_loss: 0.9562\n",
      "Epoch 4/50\n",
      "100/100 [==============================] - 0s 970us/step - loss: 0.9347 - val_loss: 0.9156\n",
      "Epoch 5/50\n",
      "100/100 [==============================] - 0s 973us/step - loss: 0.8948 - val_loss: 0.8771\n",
      "Epoch 6/50\n",
      "100/100 [==============================] - 0s 985us/step - loss: 0.8586 - val_loss: 0.8439\n",
      "Epoch 7/50\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.8271 - val_loss: 0.8150\n",
      "Epoch 8/50\n",
      "100/100 [==============================] - 0s 965us/step - loss: 0.8005 - val_loss: 0.7908\n",
      "Epoch 9/50\n",
      "100/100 [==============================] - 0s 924us/step - loss: 0.7787 - val_loss: 0.7719\n",
      "Epoch 10/50\n",
      "100/100 [==============================] - 0s 942us/step - loss: 0.7616 - val_loss: 0.7565\n",
      "Epoch 11/50\n",
      "100/100 [==============================] - 0s 929us/step - loss: 0.7476 - val_loss: 0.7445\n",
      "Epoch 12/50\n",
      "100/100 [==============================] - 0s 953us/step - loss: 0.7374 - val_loss: 0.7348\n",
      "Epoch 13/50\n",
      "100/100 [==============================] - 0s 945us/step - loss: 0.7283 - val_loss: 0.7271\n",
      "Epoch 14/50\n",
      "100/100 [==============================] - 0s 933us/step - loss: 0.7215 - val_loss: 0.7210\n",
      "Epoch 15/50\n",
      "100/100 [==============================] - 0s 945us/step - loss: 0.7165 - val_loss: 0.7174\n",
      "Epoch 16/50\n",
      "100/100 [==============================] - 0s 930us/step - loss: 0.7124 - val_loss: 0.7130\n",
      "Epoch 17/50\n",
      "100/100 [==============================] - 0s 930us/step - loss: 0.7087 - val_loss: 0.7104\n",
      "Epoch 18/50\n",
      "100/100 [==============================] - 0s 912us/step - loss: 0.7062 - val_loss: 0.7067\n",
      "Epoch 19/50\n",
      "100/100 [==============================] - 0s 924us/step - loss: 0.7030 - val_loss: 0.7042\n",
      "Epoch 20/50\n",
      "100/100 [==============================] - 0s 934us/step - loss: 0.7008 - val_loss: 0.7022\n",
      "Epoch 21/50\n",
      "100/100 [==============================] - 0s 950us/step - loss: 0.6995 - val_loss: 0.7009\n",
      "Epoch 22/50\n",
      "100/100 [==============================] - 0s 941us/step - loss: 0.6974 - val_loss: 0.6989\n",
      "Epoch 23/50\n",
      "100/100 [==============================] - 0s 971us/step - loss: 0.6957 - val_loss: 0.6988\n",
      "Epoch 24/50\n",
      "100/100 [==============================] - 0s 970us/step - loss: 0.6948 - val_loss: 0.6967\n",
      "Epoch 25/50\n",
      "100/100 [==============================] - 0s 945us/step - loss: 0.6936 - val_loss: 0.6957\n",
      "Epoch 26/50\n",
      "100/100 [==============================] - 0s 924us/step - loss: 0.6927 - val_loss: 0.6950\n",
      "Epoch 27/50\n",
      "100/100 [==============================] - 0s 923us/step - loss: 0.6920 - val_loss: 0.6942\n",
      "Epoch 28/50\n",
      "100/100 [==============================] - 0s 934us/step - loss: 0.6912 - val_loss: 0.6935\n",
      "Epoch 29/50\n",
      "100/100 [==============================] - 0s 943us/step - loss: 0.6907 - val_loss: 0.6939\n",
      "Epoch 30/50\n",
      "100/100 [==============================] - 0s 955us/step - loss: 0.6904 - val_loss: 0.6934\n",
      "Epoch 31/50\n",
      "100/100 [==============================] - 0s 942us/step - loss: 0.6903 - val_loss: 0.6933\n",
      "Epoch 32/50\n",
      "100/100 [==============================] - 0s 951us/step - loss: 0.6901 - val_loss: 0.6927\n",
      "Epoch 33/50\n",
      "100/100 [==============================] - 0s 970us/step - loss: 0.6894 - val_loss: 0.6919\n",
      "Epoch 34/50\n",
      "100/100 [==============================] - 0s 970us/step - loss: 0.6890 - val_loss: 0.6915\n",
      "Epoch 35/50\n",
      "100/100 [==============================] - 0s 953us/step - loss: 0.6888 - val_loss: 0.6923\n",
      "Epoch 36/50\n",
      "100/100 [==============================] - 0s 955us/step - loss: 0.6886 - val_loss: 0.6909\n",
      "Epoch 37/50\n",
      "100/100 [==============================] - 0s 950us/step - loss: 0.6884 - val_loss: 0.6910\n",
      "Epoch 38/50\n",
      "100/100 [==============================] - 0s 932us/step - loss: 0.6878 - val_loss: 0.6908\n",
      "Epoch 39/50\n",
      "100/100 [==============================] - 0s 940us/step - loss: 0.6877 - val_loss: 0.6903\n",
      "Epoch 40/50\n",
      "100/100 [==============================] - 0s 953us/step - loss: 0.6875 - val_loss: 0.6904\n",
      "Epoch 41/50\n",
      "100/100 [==============================] - 0s 909us/step - loss: 0.6873 - val_loss: 0.6900\n",
      "Epoch 42/50\n",
      "100/100 [==============================] - 0s 922us/step - loss: 0.6874 - val_loss: 0.6900\n",
      "Epoch 43/50\n",
      "100/100 [==============================] - 0s 914us/step - loss: 0.6871 - val_loss: 0.6902\n",
      "Epoch 44/50\n",
      "100/100 [==============================] - 0s 909us/step - loss: 0.6869 - val_loss: 0.6908\n",
      "Epoch 45/50\n",
      "100/100 [==============================] - 0s 922us/step - loss: 0.6870 - val_loss: 0.6908\n",
      "Epoch 46/50\n",
      "100/100 [==============================] - 0s 930us/step - loss: 0.6867 - val_loss: 0.6902\n",
      "Epoch 47/50\n",
      "100/100 [==============================] - 0s 912us/step - loss: 0.6867 - val_loss: 0.6911\n",
      "Epoch 48/50\n",
      "100/100 [==============================] - 0s 900us/step - loss: 0.6865 - val_loss: 0.6896\n",
      "Epoch 49/50\n",
      "100/100 [==============================] - 0s 932us/step - loss: 0.6862 - val_loss: 0.6894\n",
      "Epoch 50/50\n",
      "100/100 [==============================] - 0s 996us/step - loss: 0.6864 - val_loss: 0.6900\n",
      "100/100 [==============================] - 0s 557us/step\n",
      "25/25 [==============================] - 0s 750us/step\n",
      "0.1243749999999999\n",
      "The presence of material_advantage in resblock 0 is 0.10250000000000004\n",
      "(4000, 320)\n",
      "Performing regression for layer 1\n",
      "Epoch 1/50\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.9233 - val_loss: 0.9066\n",
      "Epoch 2/50\n",
      "100/100 [==============================] - 0s 991us/step - loss: 0.9007 - val_loss: 0.8886\n",
      "Epoch 3/50\n",
      "100/100 [==============================] - 0s 930us/step - loss: 0.8833 - val_loss: 0.8723\n",
      "Epoch 4/50\n",
      "100/100 [==============================] - 0s 951us/step - loss: 0.8668 - val_loss: 0.8567\n",
      "Epoch 5/50\n",
      "100/100 [==============================] - 0s 910us/step - loss: 0.8511 - val_loss: 0.8420\n",
      "Epoch 6/50\n",
      "100/100 [==============================] - 0s 920us/step - loss: 0.8364 - val_loss: 0.8283\n",
      "Epoch 7/50\n",
      "100/100 [==============================] - 0s 924us/step - loss: 0.8224 - val_loss: 0.8152\n",
      "Epoch 8/50\n",
      "100/100 [==============================] - 0s 904us/step - loss: 0.8092 - val_loss: 0.8029\n",
      "Epoch 9/50\n",
      "100/100 [==============================] - 0s 931us/step - loss: 0.7970 - val_loss: 0.7916\n",
      "Epoch 10/50\n",
      "100/100 [==============================] - 0s 904us/step - loss: 0.7857 - val_loss: 0.7810\n",
      "Epoch 11/50\n",
      "100/100 [==============================] - 0s 935us/step - loss: 0.7753 - val_loss: 0.7714\n",
      "Epoch 12/50\n",
      "100/100 [==============================] - 0s 940us/step - loss: 0.7660 - val_loss: 0.7629\n",
      "Epoch 13/50\n",
      "100/100 [==============================] - 0s 910us/step - loss: 0.7579 - val_loss: 0.7553\n",
      "Epoch 14/50\n",
      "100/100 [==============================] - 0s 919us/step - loss: 0.7503 - val_loss: 0.7481\n",
      "Epoch 15/50\n",
      "100/100 [==============================] - 0s 970us/step - loss: 0.7435 - val_loss: 0.7421\n",
      "Epoch 16/50\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.7379 - val_loss: 0.7369\n",
      "Epoch 17/50\n",
      "100/100 [==============================] - 0s 950us/step - loss: 0.7329 - val_loss: 0.7325\n",
      "Epoch 18/50\n",
      "100/100 [==============================] - 0s 919us/step - loss: 0.7286 - val_loss: 0.7283\n",
      "Epoch 19/50\n",
      "100/100 [==============================] - 0s 884us/step - loss: 0.7250 - val_loss: 0.7250\n",
      "Epoch 20/50\n",
      "100/100 [==============================] - 0s 880us/step - loss: 0.7218 - val_loss: 0.7219\n",
      "Epoch 21/50\n",
      "100/100 [==============================] - 0s 890us/step - loss: 0.7189 - val_loss: 0.7192\n",
      "Epoch 22/50\n",
      "100/100 [==============================] - 0s 900us/step - loss: 0.7163 - val_loss: 0.7168\n",
      "Epoch 23/50\n",
      "100/100 [==============================] - 0s 891us/step - loss: 0.7140 - val_loss: 0.7145\n",
      "Epoch 24/50\n",
      "100/100 [==============================] - 0s 870us/step - loss: 0.7118 - val_loss: 0.7123\n",
      "Epoch 25/50\n",
      "100/100 [==============================] - 0s 874us/step - loss: 0.7097 - val_loss: 0.7104\n",
      "Epoch 26/50\n",
      "100/100 [==============================] - 0s 874us/step - loss: 0.7078 - val_loss: 0.7085\n",
      "Epoch 27/50\n",
      "100/100 [==============================] - 0s 894us/step - loss: 0.7061 - val_loss: 0.7068\n",
      "Epoch 28/50\n",
      "100/100 [==============================] - 0s 869us/step - loss: 0.7044 - val_loss: 0.7053\n",
      "Epoch 29/50\n",
      "100/100 [==============================] - 0s 874us/step - loss: 0.7030 - val_loss: 0.7039\n",
      "Epoch 30/50\n",
      "100/100 [==============================] - 0s 874us/step - loss: 0.7017 - val_loss: 0.7026\n",
      "Epoch 31/50\n",
      "100/100 [==============================] - 0s 894us/step - loss: 0.7006 - val_loss: 0.7016\n",
      "Epoch 32/50\n",
      "100/100 [==============================] - 0s 890us/step - loss: 0.6996 - val_loss: 0.7008\n",
      "Epoch 33/50\n",
      "100/100 [==============================] - 0s 879us/step - loss: 0.6987 - val_loss: 0.6998\n",
      "Epoch 34/50\n",
      "100/100 [==============================] - 0s 890us/step - loss: 0.6978 - val_loss: 0.6989\n",
      "Epoch 35/50\n",
      "100/100 [==============================] - 0s 874us/step - loss: 0.6970 - val_loss: 0.6981\n",
      "Epoch 36/50\n",
      "100/100 [==============================] - 0s 874us/step - loss: 0.6966 - val_loss: 0.6975\n",
      "Epoch 37/50\n",
      "100/100 [==============================] - 0s 880us/step - loss: 0.6957 - val_loss: 0.6968\n",
      "Epoch 38/50\n",
      "100/100 [==============================] - 0s 939us/step - loss: 0.6952 - val_loss: 0.6962\n",
      "Epoch 39/50\n",
      "100/100 [==============================] - 0s 879us/step - loss: 0.6947 - val_loss: 0.6960\n",
      "Epoch 40/50\n",
      "100/100 [==============================] - 0s 879us/step - loss: 0.6943 - val_loss: 0.6953\n",
      "Epoch 41/50\n",
      "100/100 [==============================] - 0s 893us/step - loss: 0.6940 - val_loss: 0.6949\n",
      "Epoch 42/50\n",
      "100/100 [==============================] - 0s 914us/step - loss: 0.6935 - val_loss: 0.6945\n",
      "Epoch 43/50\n",
      "100/100 [==============================] - 0s 980us/step - loss: 0.6932 - val_loss: 0.6941\n",
      "Epoch 44/50\n",
      "100/100 [==============================] - 0s 970us/step - loss: 0.6929 - val_loss: 0.6938\n",
      "Epoch 45/50\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6927 - val_loss: 0.6937\n",
      "Epoch 46/50\n",
      "100/100 [==============================] - 0s 889us/step - loss: 0.6925 - val_loss: 0.6934\n",
      "Epoch 47/50\n",
      "100/100 [==============================] - 0s 873us/step - loss: 0.6922 - val_loss: 0.6932\n",
      "Epoch 48/50\n",
      "100/100 [==============================] - 0s 894us/step - loss: 0.6920 - val_loss: 0.6929\n",
      "Epoch 49/50\n",
      "100/100 [==============================] - 0s 893us/step - loss: 0.6918 - val_loss: 0.6927\n",
      "Epoch 50/50\n",
      "100/100 [==============================] - 0s 874us/step - loss: 0.6916 - val_loss: 0.6926\n",
      "100/100 [==============================] - 0s 485us/step\n",
      "25/25 [==============================] - 0s 500us/step\n",
      "0.11312499999999992\n",
      "The presence of material_advantage in resblock 1 is 0.10499999999999998\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2004it [00:37, 75.14it/s]                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting outputs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 125/125 [00:01<00:00, 94.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merging outputs...\n",
      "Outputs merged.\n",
      "(4000, 980)\n",
      "Performing regression for layer 0\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 0s 2ms/step - loss: 1.0923 - val_loss: 1.0768\n",
      "Epoch 2/50\n",
      "100/100 [==============================] - 0s 901us/step - loss: 1.0562 - val_loss: 1.0459\n",
      "Epoch 3/50\n",
      "100/100 [==============================] - 0s 914us/step - loss: 1.0263 - val_loss: 1.0168\n",
      "Epoch 4/50\n",
      "100/100 [==============================] - 0s 904us/step - loss: 0.9993 - val_loss: 0.9851\n",
      "Epoch 5/50\n",
      "100/100 [==============================] - 0s 910us/step - loss: 0.9738 - val_loss: 0.9630\n",
      "Epoch 6/50\n",
      "100/100 [==============================] - 0s 953us/step - loss: 0.9490 - val_loss: 0.9369\n",
      "Epoch 7/50\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.9280 - val_loss: 0.9170\n",
      "Epoch 8/50\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.9078 - val_loss: 0.9065\n",
      "Epoch 9/50\n",
      "100/100 [==============================] - 0s 985us/step - loss: 0.8913 - val_loss: 0.8808\n",
      "Epoch 10/50\n",
      "100/100 [==============================] - 0s 955us/step - loss: 0.8734 - val_loss: 0.8758\n",
      "Epoch 11/50\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.8581 - val_loss: 0.8523\n",
      "Epoch 12/50\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.8433 - val_loss: 0.8374\n",
      "Epoch 13/50\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.8302 - val_loss: 0.8228\n",
      "Epoch 14/50\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.8184 - val_loss: 0.8120\n",
      "Epoch 15/50\n",
      "100/100 [==============================] - 0s 982us/step - loss: 0.8067 - val_loss: 0.8022\n",
      "Epoch 16/50\n",
      "100/100 [==============================] - 0s 960us/step - loss: 0.7965 - val_loss: 0.7963\n",
      "Epoch 17/50\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.7870 - val_loss: 0.7830\n",
      "Epoch 18/50\n",
      "100/100 [==============================] - 0s 962us/step - loss: 0.7791 - val_loss: 0.7761\n",
      "Epoch 19/50\n",
      "100/100 [==============================] - 0s 960us/step - loss: 0.7716 - val_loss: 0.7715\n",
      "Epoch 20/50\n",
      "100/100 [==============================] - 0s 951us/step - loss: 0.7640 - val_loss: 0.7633\n",
      "Epoch 21/50\n",
      "100/100 [==============================] - 0s 921us/step - loss: 0.7582 - val_loss: 0.7611\n",
      "Epoch 22/50\n",
      "100/100 [==============================] - 0s 921us/step - loss: 0.7521 - val_loss: 0.7501\n",
      "Epoch 23/50\n",
      "100/100 [==============================] - 0s 971us/step - loss: 0.7467 - val_loss: 0.7597\n",
      "Epoch 24/50\n",
      "100/100 [==============================] - 0s 965us/step - loss: 0.7422 - val_loss: 0.7407\n",
      "Epoch 25/50\n",
      "100/100 [==============================] - 0s 934us/step - loss: 0.7363 - val_loss: 0.7354\n",
      "Epoch 26/50\n",
      "100/100 [==============================] - 0s 925us/step - loss: 0.7327 - val_loss: 0.7355\n",
      "Epoch 27/50\n",
      "100/100 [==============================] - 0s 904us/step - loss: 0.7285 - val_loss: 0.7284\n",
      "Epoch 28/50\n",
      "100/100 [==============================] - 0s 920us/step - loss: 0.7252 - val_loss: 0.7263\n",
      "Epoch 29/50\n",
      "100/100 [==============================] - 0s 961us/step - loss: 0.7216 - val_loss: 0.7224\n",
      "Epoch 30/50\n",
      "100/100 [==============================] - 0s 940us/step - loss: 0.7192 - val_loss: 0.7188\n",
      "Epoch 31/50\n",
      "100/100 [==============================] - 0s 960us/step - loss: 0.7160 - val_loss: 0.7166\n",
      "Epoch 32/50\n",
      "100/100 [==============================] - 0s 982us/step - loss: 0.7150 - val_loss: 0.7162\n",
      "Epoch 33/50\n",
      "100/100 [==============================] - 0s 952us/step - loss: 0.7112 - val_loss: 0.7108\n",
      "Epoch 34/50\n",
      "100/100 [==============================] - 0s 946us/step - loss: 0.7100 - val_loss: 0.7097\n",
      "Epoch 35/50\n",
      "100/100 [==============================] - 0s 972us/step - loss: 0.7067 - val_loss: 0.7099\n",
      "Epoch 36/50\n",
      "100/100 [==============================] - 0s 941us/step - loss: 0.7056 - val_loss: 0.7068\n",
      "Epoch 37/50\n",
      "100/100 [==============================] - 0s 901us/step - loss: 0.7055 - val_loss: 0.7091\n",
      "Epoch 38/50\n",
      "100/100 [==============================] - 0s 890us/step - loss: 0.7025 - val_loss: 0.7029\n",
      "Epoch 39/50\n",
      "100/100 [==============================] - 0s 884us/step - loss: 0.7010 - val_loss: 0.7066\n",
      "Epoch 40/50\n",
      "100/100 [==============================] - 0s 914us/step - loss: 0.7012 - val_loss: 0.7021\n",
      "Epoch 41/50\n",
      "100/100 [==============================] - 0s 920us/step - loss: 0.6991 - val_loss: 0.7012\n",
      "Epoch 42/50\n",
      "100/100 [==============================] - 0s 904us/step - loss: 0.6990 - val_loss: 0.6987\n",
      "Epoch 43/50\n",
      "100/100 [==============================] - 0s 935us/step - loss: 0.6970 - val_loss: 0.6982\n",
      "Epoch 44/50\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6962 - val_loss: 0.6987\n",
      "Epoch 45/50\n",
      "100/100 [==============================] - 0s 930us/step - loss: 0.6944 - val_loss: 0.7025\n",
      "Epoch 46/50\n",
      "100/100 [==============================] - 0s 931us/step - loss: 0.6939 - val_loss: 0.6966\n",
      "Epoch 47/50\n",
      "100/100 [==============================] - 0s 960us/step - loss: 0.6939 - val_loss: 0.6954\n",
      "Epoch 48/50\n",
      "100/100 [==============================] - 0s 945us/step - loss: 0.6931 - val_loss: 0.6965\n",
      "Epoch 49/50\n",
      "100/100 [==============================] - 0s 935us/step - loss: 0.6913 - val_loss: 0.7059\n",
      "Epoch 50/50\n",
      "100/100 [==============================] - 0s 935us/step - loss: 0.6923 - val_loss: 0.6991\n",
      "100/100 [==============================] - 0s 480us/step\n",
      "25/25 [==============================] - 0s 500us/step\n",
      "0.2137500000000001\n",
      "The presence of material_advantage in resblock 0 is 0.1825000000000001\n",
      "(4000, 320)\n",
      "Performing regression for layer 1\n",
      "Epoch 1/50\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 1.0027 - val_loss: 0.9463\n",
      "Epoch 2/50\n",
      "100/100 [==============================] - 0s 904us/step - loss: 0.9426 - val_loss: 0.9265\n",
      "Epoch 3/50\n",
      "100/100 [==============================] - 0s 972us/step - loss: 0.9312 - val_loss: 0.9161\n",
      "Epoch 4/50\n",
      "100/100 [==============================] - 0s 934us/step - loss: 0.9203 - val_loss: 0.9048\n",
      "Epoch 5/50\n",
      "100/100 [==============================] - 0s 904us/step - loss: 0.9098 - val_loss: 0.8966\n",
      "Epoch 6/50\n",
      "100/100 [==============================] - 0s 894us/step - loss: 0.8994 - val_loss: 0.8853\n",
      "Epoch 7/50\n",
      "100/100 [==============================] - 0s 924us/step - loss: 0.8891 - val_loss: 0.8748\n",
      "Epoch 8/50\n",
      "100/100 [==============================] - 0s 941us/step - loss: 0.8790 - val_loss: 0.8664\n",
      "Epoch 9/50\n",
      "100/100 [==============================] - 0s 918us/step - loss: 0.8695 - val_loss: 0.8582\n",
      "Epoch 10/50\n",
      "100/100 [==============================] - 0s 940us/step - loss: 0.8599 - val_loss: 0.8498\n",
      "Epoch 11/50\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.8511 - val_loss: 0.8418\n",
      "Epoch 12/50\n",
      "100/100 [==============================] - 0s 930us/step - loss: 0.8427 - val_loss: 0.8334\n",
      "Epoch 13/50\n",
      "100/100 [==============================] - 0s 950us/step - loss: 0.8344 - val_loss: 0.8254\n",
      "Epoch 14/50\n",
      "100/100 [==============================] - 0s 970us/step - loss: 0.8266 - val_loss: 0.8184\n",
      "Epoch 15/50\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.8193 - val_loss: 0.8131\n",
      "Epoch 16/50\n",
      "100/100 [==============================] - 0s 950us/step - loss: 0.8126 - val_loss: 0.8061\n",
      "Epoch 17/50\n",
      "100/100 [==============================] - 0s 970us/step - loss: 0.8058 - val_loss: 0.8003\n",
      "Epoch 18/50\n",
      "100/100 [==============================] - 0s 899us/step - loss: 0.7994 - val_loss: 0.7957\n",
      "Epoch 19/50\n",
      "100/100 [==============================] - 0s 879us/step - loss: 0.7937 - val_loss: 0.7890\n",
      "Epoch 20/50\n",
      "100/100 [==============================] - 0s 904us/step - loss: 0.7879 - val_loss: 0.7871\n",
      "Epoch 21/50\n",
      "100/100 [==============================] - 0s 924us/step - loss: 0.7832 - val_loss: 0.7782\n",
      "Epoch 22/50\n",
      "100/100 [==============================] - 0s 904us/step - loss: 0.7782 - val_loss: 0.7741\n",
      "Epoch 23/50\n",
      "100/100 [==============================] - 0s 904us/step - loss: 0.7737 - val_loss: 0.7712\n",
      "Epoch 24/50\n",
      "100/100 [==============================] - 0s 910us/step - loss: 0.7699 - val_loss: 0.7670\n",
      "Epoch 25/50\n",
      "100/100 [==============================] - 0s 909us/step - loss: 0.7655 - val_loss: 0.7639\n",
      "Epoch 26/50\n",
      "100/100 [==============================] - 0s 900us/step - loss: 0.7617 - val_loss: 0.7588\n",
      "Epoch 27/50\n",
      "100/100 [==============================] - 0s 904us/step - loss: 0.7580 - val_loss: 0.7555\n",
      "Epoch 28/50\n",
      "100/100 [==============================] - 0s 965us/step - loss: 0.7545 - val_loss: 0.7533\n",
      "Epoch 29/50\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.7515 - val_loss: 0.7504\n",
      "Epoch 30/50\n",
      "100/100 [==============================] - 0s 902us/step - loss: 0.7485 - val_loss: 0.7470\n",
      "Epoch 31/50\n",
      "100/100 [==============================] - 0s 913us/step - loss: 0.7455 - val_loss: 0.7444\n",
      "Epoch 32/50\n",
      "100/100 [==============================] - 0s 909us/step - loss: 0.7433 - val_loss: 0.7421\n",
      "Epoch 33/50\n",
      "100/100 [==============================] - 0s 899us/step - loss: 0.7404 - val_loss: 0.7394\n",
      "Epoch 34/50\n",
      "100/100 [==============================] - 0s 902us/step - loss: 0.7380 - val_loss: 0.7377\n",
      "Epoch 35/50\n",
      "100/100 [==============================] - 0s 882us/step - loss: 0.7356 - val_loss: 0.7356\n",
      "Epoch 36/50\n",
      "100/100 [==============================] - 0s 921us/step - loss: 0.7338 - val_loss: 0.7335\n",
      "Epoch 37/50\n",
      "100/100 [==============================] - 0s 914us/step - loss: 0.7316 - val_loss: 0.7320\n",
      "Epoch 38/50\n",
      "100/100 [==============================] - 0s 884us/step - loss: 0.7298 - val_loss: 0.7294\n",
      "Epoch 39/50\n",
      "100/100 [==============================] - 0s 940us/step - loss: 0.7279 - val_loss: 0.7287\n",
      "Epoch 40/50\n",
      "100/100 [==============================] - 0s 930us/step - loss: 0.7263 - val_loss: 0.7276\n",
      "Epoch 41/50\n",
      "100/100 [==============================] - 0s 910us/step - loss: 0.7245 - val_loss: 0.7241\n",
      "Epoch 42/50\n",
      "100/100 [==============================] - 0s 892us/step - loss: 0.7230 - val_loss: 0.7230\n",
      "Epoch 43/50\n",
      "100/100 [==============================] - 0s 901us/step - loss: 0.7210 - val_loss: 0.7212\n",
      "Epoch 44/50\n",
      "100/100 [==============================] - 0s 879us/step - loss: 0.7201 - val_loss: 0.7193\n",
      "Epoch 45/50\n",
      "100/100 [==============================] - 0s 879us/step - loss: 0.7179 - val_loss: 0.7204\n",
      "Epoch 46/50\n",
      "100/100 [==============================] - 0s 934us/step - loss: 0.7164 - val_loss: 0.7166\n",
      "Epoch 47/50\n",
      "100/100 [==============================] - 0s 914us/step - loss: 0.7149 - val_loss: 0.7159\n",
      "Epoch 48/50\n",
      "100/100 [==============================] - 0s 900us/step - loss: 0.7135 - val_loss: 0.7140\n",
      "Epoch 49/50\n",
      "100/100 [==============================] - 0s 890us/step - loss: 0.7120 - val_loss: 0.7131\n",
      "Epoch 50/50\n",
      "100/100 [==============================] - 0s 903us/step - loss: 0.7108 - val_loss: 0.7110\n",
      "100/100 [==============================] - 0s 480us/step\n",
      "25/25 [==============================] - 0s 516us/step\n",
      "0.1937500000000001\n",
      "The presence of material_advantage in resblock 1 is 0.15250000000000008\n",
      "Getting outputs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 125/125 [00:01<00:00, 95.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merging outputs...\n",
      "Outputs merged.\n",
      "(4000, 980)\n",
      "Performing regression for layer 0\n",
      "Epoch 1/50\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 1.0904 - val_loss: 1.0734\n",
      "Epoch 2/50\n",
      "100/100 [==============================] - 0s 963us/step - loss: 1.0694 - val_loss: 1.0546\n",
      "Epoch 3/50\n",
      "100/100 [==============================] - 0s 955us/step - loss: 1.0507 - val_loss: 1.0401\n",
      "Epoch 4/50\n",
      "100/100 [==============================] - 0s 924us/step - loss: 1.0336 - val_loss: 1.0211\n",
      "Epoch 5/50\n",
      "100/100 [==============================] - 0s 914us/step - loss: 1.0155 - val_loss: 1.0073\n",
      "Epoch 6/50\n",
      "100/100 [==============================] - 0s 932us/step - loss: 1.0009 - val_loss: 0.9920\n",
      "Epoch 7/50\n",
      "100/100 [==============================] - 0s 921us/step - loss: 0.9875 - val_loss: 0.9772\n",
      "Epoch 8/50\n",
      "100/100 [==============================] - 0s 903us/step - loss: 0.9741 - val_loss: 0.9673\n",
      "Epoch 9/50\n",
      "100/100 [==============================] - 0s 924us/step - loss: 0.9606 - val_loss: 0.9510\n",
      "Epoch 10/50\n",
      "100/100 [==============================] - 0s 901us/step - loss: 0.9457 - val_loss: 0.9393\n",
      "Epoch 11/50\n",
      "100/100 [==============================] - 0s 894us/step - loss: 0.9342 - val_loss: 0.9279\n",
      "Epoch 12/50\n",
      "100/100 [==============================] - 0s 904us/step - loss: 0.9227 - val_loss: 0.9171\n",
      "Epoch 13/50\n",
      "100/100 [==============================] - 0s 910us/step - loss: 0.9128 - val_loss: 0.9079\n",
      "Epoch 14/50\n",
      "100/100 [==============================] - 0s 899us/step - loss: 0.9039 - val_loss: 0.8998\n",
      "Epoch 15/50\n",
      "100/100 [==============================] - 0s 904us/step - loss: 0.8915 - val_loss: 0.8877\n",
      "Epoch 16/50\n",
      "100/100 [==============================] - 0s 904us/step - loss: 0.8818 - val_loss: 0.8797\n",
      "Epoch 17/50\n",
      "100/100 [==============================] - 0s 920us/step - loss: 0.8727 - val_loss: 0.8714\n",
      "Epoch 18/50\n",
      "100/100 [==============================] - 0s 904us/step - loss: 0.8643 - val_loss: 0.8613\n",
      "Epoch 19/50\n",
      "100/100 [==============================] - 0s 904us/step - loss: 0.8563 - val_loss: 0.8534\n",
      "Epoch 20/50\n",
      "100/100 [==============================] - 0s 930us/step - loss: 0.8474 - val_loss: 0.8454\n",
      "Epoch 21/50\n",
      "100/100 [==============================] - 0s 980us/step - loss: 0.8396 - val_loss: 0.8376\n",
      "Epoch 22/50\n",
      "100/100 [==============================] - 0s 922us/step - loss: 0.8327 - val_loss: 0.8307\n",
      "Epoch 23/50\n",
      "100/100 [==============================] - 0s 920us/step - loss: 0.8273 - val_loss: 0.8247\n",
      "Epoch 24/50\n",
      "100/100 [==============================] - 0s 921us/step - loss: 0.8190 - val_loss: 0.8169\n",
      "Epoch 25/50\n",
      "100/100 [==============================] - 0s 932us/step - loss: 0.8116 - val_loss: 0.8105\n",
      "Epoch 26/50\n",
      "100/100 [==============================] - 0s 914us/step - loss: 0.8057 - val_loss: 0.8044\n",
      "Epoch 27/50\n",
      "100/100 [==============================] - 0s 924us/step - loss: 0.7998 - val_loss: 0.7987\n",
      "Epoch 28/50\n",
      "100/100 [==============================] - 0s 930us/step - loss: 0.7977 - val_loss: 0.7943\n",
      "Epoch 29/50\n",
      "100/100 [==============================] - 0s 902us/step - loss: 0.7880 - val_loss: 0.7880\n",
      "Epoch 30/50\n",
      "100/100 [==============================] - 0s 919us/step - loss: 0.7849 - val_loss: 0.7872\n",
      "Epoch 31/50\n",
      "100/100 [==============================] - 0s 902us/step - loss: 0.7777 - val_loss: 0.7778\n",
      "Epoch 32/50\n",
      "100/100 [==============================] - 0s 904us/step - loss: 0.7726 - val_loss: 0.7735\n",
      "Epoch 33/50\n",
      "100/100 [==============================] - 0s 909us/step - loss: 0.7685 - val_loss: 0.7708\n",
      "Epoch 34/50\n",
      "100/100 [==============================] - 0s 889us/step - loss: 0.7640 - val_loss: 0.7641\n",
      "Epoch 35/50\n",
      "100/100 [==============================] - 0s 900us/step - loss: 0.7597 - val_loss: 0.7611\n",
      "Epoch 36/50\n",
      "100/100 [==============================] - 0s 901us/step - loss: 0.7572 - val_loss: 0.7574\n",
      "Epoch 37/50\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.7516 - val_loss: 0.7526\n",
      "Epoch 38/50\n",
      "100/100 [==============================] - 0s 930us/step - loss: 0.7472 - val_loss: 0.7502\n",
      "Epoch 39/50\n",
      "100/100 [==============================] - 0s 920us/step - loss: 0.7475 - val_loss: 0.7459\n",
      "Epoch 40/50\n",
      "100/100 [==============================] - 0s 899us/step - loss: 0.7404 - val_loss: 0.7426\n",
      "Epoch 41/50\n",
      "100/100 [==============================] - 0s 894us/step - loss: 0.7381 - val_loss: 0.7424\n",
      "Epoch 42/50\n",
      "100/100 [==============================] - 0s 904us/step - loss: 0.7380 - val_loss: 0.7403\n",
      "Epoch 43/50\n",
      "100/100 [==============================] - 0s 902us/step - loss: 0.7335 - val_loss: 0.7361\n",
      "Epoch 44/50\n",
      "100/100 [==============================] - 0s 919us/step - loss: 0.7300 - val_loss: 0.7320\n",
      "Epoch 45/50\n",
      "100/100 [==============================] - 0s 919us/step - loss: 0.7288 - val_loss: 0.7306\n",
      "Epoch 46/50\n",
      "100/100 [==============================] - 0s 894us/step - loss: 0.7252 - val_loss: 0.7278\n",
      "Epoch 47/50\n",
      "100/100 [==============================] - 0s 914us/step - loss: 0.7249 - val_loss: 0.7265\n",
      "Epoch 48/50\n",
      "100/100 [==============================] - 0s 914us/step - loss: 0.7216 - val_loss: 0.7249\n",
      "Epoch 49/50\n",
      "100/100 [==============================] - 0s 904us/step - loss: 0.7201 - val_loss: 0.7264\n",
      "Epoch 50/50\n",
      "100/100 [==============================] - 0s 930us/step - loss: 0.7187 - val_loss: 0.7292\n",
      "100/100 [==============================] - 0s 485us/step\n",
      "25/25 [==============================] - 0s 542us/step\n",
      "0.17625000000000002\n",
      "The presence of material_advantage in resblock 0 is 0.17999999999999994\n",
      "(4000, 320)\n",
      "Performing regression for layer 1\n",
      "Epoch 1/50\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.9119 - val_loss: 0.8895\n",
      "Epoch 2/50\n",
      "100/100 [==============================] - 0s 874us/step - loss: 0.8906 - val_loss: 0.8803\n",
      "Epoch 3/50\n",
      "100/100 [==============================] - 0s 880us/step - loss: 0.8809 - val_loss: 0.8713\n",
      "Epoch 4/50\n",
      "100/100 [==============================] - 0s 882us/step - loss: 0.8720 - val_loss: 0.8631\n",
      "Epoch 5/50\n",
      "100/100 [==============================] - 0s 931us/step - loss: 0.8632 - val_loss: 0.8554\n",
      "Epoch 6/50\n",
      "100/100 [==============================] - 0s 904us/step - loss: 0.8551 - val_loss: 0.8475\n",
      "Epoch 7/50\n",
      "100/100 [==============================] - 0s 874us/step - loss: 0.8472 - val_loss: 0.8411\n",
      "Epoch 8/50\n",
      "100/100 [==============================] - 0s 880us/step - loss: 0.8397 - val_loss: 0.8332\n",
      "Epoch 9/50\n",
      "100/100 [==============================] - 0s 891us/step - loss: 0.8325 - val_loss: 0.8264\n",
      "Epoch 10/50\n",
      "100/100 [==============================] - 0s 879us/step - loss: 0.8254 - val_loss: 0.8199\n",
      "Epoch 11/50\n",
      "100/100 [==============================] - 0s 872us/step - loss: 0.8186 - val_loss: 0.8135\n",
      "Epoch 12/50\n",
      "100/100 [==============================] - 0s 871us/step - loss: 0.8122 - val_loss: 0.8079\n",
      "Epoch 13/50\n",
      "100/100 [==============================] - 0s 916us/step - loss: 0.8057 - val_loss: 0.8016\n",
      "Epoch 14/50\n",
      "100/100 [==============================] - 0s 904us/step - loss: 0.7995 - val_loss: 0.7959\n",
      "Epoch 15/50\n",
      "100/100 [==============================] - 0s 961us/step - loss: 0.7934 - val_loss: 0.7905\n",
      "Epoch 16/50\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.7880 - val_loss: 0.7852\n",
      "Epoch 17/50\n",
      "100/100 [==============================] - 0s 911us/step - loss: 0.7828 - val_loss: 0.7804\n",
      "Epoch 18/50\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.7779 - val_loss: 0.7762\n",
      "Epoch 19/50\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.7730 - val_loss: 0.7713\n",
      "Epoch 20/50\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.7684 - val_loss: 0.7671\n",
      "Epoch 21/50\n",
      "100/100 [==============================] - 0s 924us/step - loss: 0.7641 - val_loss: 0.7632\n",
      "Epoch 22/50\n",
      "100/100 [==============================] - 0s 904us/step - loss: 0.7600 - val_loss: 0.7587\n",
      "Epoch 23/50\n",
      "100/100 [==============================] - 0s 920us/step - loss: 0.7557 - val_loss: 0.7548\n",
      "Epoch 24/50\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.7516 - val_loss: 0.7507\n",
      "Epoch 25/50\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.7475 - val_loss: 0.7471\n",
      "Epoch 26/50\n",
      "100/100 [==============================] - 0s 964us/step - loss: 0.7436 - val_loss: 0.7432\n",
      "Epoch 27/50\n",
      "100/100 [==============================] - 0s 945us/step - loss: 0.7403 - val_loss: 0.7399\n",
      "Epoch 28/50\n",
      "100/100 [==============================] - 0s 965us/step - loss: 0.7366 - val_loss: 0.7365\n",
      "Epoch 29/50\n",
      "100/100 [==============================] - 0s 894us/step - loss: 0.7333 - val_loss: 0.7334\n",
      "Epoch 30/50\n",
      "100/100 [==============================] - 0s 894us/step - loss: 0.7301 - val_loss: 0.7312\n",
      "Epoch 31/50\n",
      "100/100 [==============================] - 0s 904us/step - loss: 0.7271 - val_loss: 0.7273\n",
      "Epoch 32/50\n",
      "100/100 [==============================] - 0s 880us/step - loss: 0.7246 - val_loss: 0.7245\n",
      "Epoch 33/50\n",
      "100/100 [==============================] - 0s 880us/step - loss: 0.7215 - val_loss: 0.7218\n",
      "Epoch 34/50\n",
      "100/100 [==============================] - 0s 889us/step - loss: 0.7191 - val_loss: 0.7192\n",
      "Epoch 35/50\n",
      "100/100 [==============================] - 0s 892us/step - loss: 0.7166 - val_loss: 0.7174\n",
      "Epoch 36/50\n",
      "100/100 [==============================] - 0s 884us/step - loss: 0.7149 - val_loss: 0.7160\n",
      "Epoch 37/50\n",
      "100/100 [==============================] - 0s 919us/step - loss: 0.7129 - val_loss: 0.7146\n",
      "Epoch 38/50\n",
      "100/100 [==============================] - 0s 883us/step - loss: 0.7111 - val_loss: 0.7115\n",
      "Epoch 39/50\n",
      "100/100 [==============================] - 0s 884us/step - loss: 0.7092 - val_loss: 0.7098\n",
      "Epoch 40/50\n",
      "100/100 [==============================] - 0s 882us/step - loss: 0.7078 - val_loss: 0.7080\n",
      "Epoch 41/50\n",
      "100/100 [==============================] - 0s 899us/step - loss: 0.7062 - val_loss: 0.7065\n",
      "Epoch 42/50\n",
      "100/100 [==============================] - 0s 891us/step - loss: 0.7047 - val_loss: 0.7051\n",
      "Epoch 43/50\n",
      "100/100 [==============================] - 0s 871us/step - loss: 0.7033 - val_loss: 0.7038\n",
      "Epoch 44/50\n",
      "100/100 [==============================] - 0s 879us/step - loss: 0.7017 - val_loss: 0.7028\n",
      "Epoch 45/50\n",
      "100/100 [==============================] - 0s 874us/step - loss: 0.7004 - val_loss: 0.7011\n",
      "Epoch 46/50\n",
      "100/100 [==============================] - 0s 884us/step - loss: 0.6994 - val_loss: 0.6999\n",
      "Epoch 47/50\n",
      "100/100 [==============================] - 0s 899us/step - loss: 0.6983 - val_loss: 0.6988\n",
      "Epoch 48/50\n",
      "100/100 [==============================] - 0s 942us/step - loss: 0.6971 - val_loss: 0.6983\n",
      "Epoch 49/50\n",
      "100/100 [==============================] - 0s 911us/step - loss: 0.6960 - val_loss: 0.6970\n",
      "Epoch 50/50\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6951 - val_loss: 0.6961\n",
      "100/100 [==============================] - 0s 535us/step\n",
      "25/25 [==============================] - 0s 500us/step\n",
      "0.23875000000000002\n",
      "The presence of material_advantage in resblock 1 is 0.2549999999999999\n",
      "Getting outputs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 125/125 [00:01<00:00, 94.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merging outputs...\n",
      "Outputs merged.\n",
      "(4000, 980)\n",
      "Performing regression for layer 0\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 0s 2ms/step - loss: 1.0933 - val_loss: 1.0797\n",
      "Epoch 2/50\n",
      "100/100 [==============================] - 0s 923us/step - loss: 1.0630 - val_loss: 1.0601\n",
      "Epoch 3/50\n",
      "100/100 [==============================] - 0s 945us/step - loss: 1.0462 - val_loss: 1.0441\n",
      "Epoch 4/50\n",
      "100/100 [==============================] - 0s 974us/step - loss: 1.0308 - val_loss: 1.0353\n",
      "Epoch 5/50\n",
      "100/100 [==============================] - 0s 975us/step - loss: 1.0149 - val_loss: 1.0166\n",
      "Epoch 6/50\n",
      "100/100 [==============================] - 0s 972us/step - loss: 0.9999 - val_loss: 1.0040\n",
      "Epoch 7/50\n",
      "100/100 [==============================] - 0s 930us/step - loss: 0.9865 - val_loss: 0.9916\n",
      "Epoch 8/50\n",
      "100/100 [==============================] - 0s 900us/step - loss: 0.9747 - val_loss: 0.9827\n",
      "Epoch 9/50\n",
      "100/100 [==============================] - 0s 899us/step - loss: 0.9606 - val_loss: 0.9727\n",
      "Epoch 10/50\n",
      "100/100 [==============================] - 0s 921us/step - loss: 0.9495 - val_loss: 0.9614\n",
      "Epoch 11/50\n",
      "100/100 [==============================] - 0s 903us/step - loss: 0.9380 - val_loss: 0.9462\n",
      "Epoch 12/50\n",
      "100/100 [==============================] - 0s 894us/step - loss: 0.9260 - val_loss: 0.9408\n",
      "Epoch 13/50\n",
      "100/100 [==============================] - 0s 934us/step - loss: 0.9164 - val_loss: 0.9264\n",
      "Epoch 14/50\n",
      "100/100 [==============================] - 0s 904us/step - loss: 0.9058 - val_loss: 0.9162\n",
      "Epoch 15/50\n",
      "100/100 [==============================] - 0s 914us/step - loss: 0.8952 - val_loss: 0.9062\n",
      "Epoch 16/50\n",
      "100/100 [==============================] - 0s 914us/step - loss: 0.8861 - val_loss: 0.8969\n",
      "Epoch 17/50\n",
      "100/100 [==============================] - 0s 930us/step - loss: 0.8781 - val_loss: 0.8881\n",
      "Epoch 18/50\n",
      "100/100 [==============================] - 0s 909us/step - loss: 0.8681 - val_loss: 0.8796\n",
      "Epoch 19/50\n",
      "100/100 [==============================] - 0s 909us/step - loss: 0.8607 - val_loss: 0.8714\n",
      "Epoch 20/50\n",
      "100/100 [==============================] - 0s 920us/step - loss: 0.8511 - val_loss: 0.8645\n",
      "Epoch 21/50\n",
      "100/100 [==============================] - 0s 912us/step - loss: 0.8451 - val_loss: 0.8558\n",
      "Epoch 22/50\n",
      "100/100 [==============================] - 0s 922us/step - loss: 0.8361 - val_loss: 0.8491\n",
      "Epoch 23/50\n",
      "100/100 [==============================] - 0s 973us/step - loss: 0.8281 - val_loss: 0.8417\n",
      "Epoch 24/50\n",
      "100/100 [==============================] - 0s 924us/step - loss: 0.8228 - val_loss: 0.8354\n",
      "Epoch 25/50\n",
      "100/100 [==============================] - 0s 943us/step - loss: 0.8165 - val_loss: 0.8290\n",
      "Epoch 26/50\n",
      "100/100 [==============================] - 0s 914us/step - loss: 0.8103 - val_loss: 0.8225\n",
      "Epoch 27/50\n",
      "100/100 [==============================] - 0s 922us/step - loss: 0.8035 - val_loss: 0.8176\n",
      "Epoch 28/50\n",
      "100/100 [==============================] - 0s 955us/step - loss: 0.7977 - val_loss: 0.8115\n",
      "Epoch 29/50\n",
      "100/100 [==============================] - 0s 964us/step - loss: 0.7940 - val_loss: 0.8059\n",
      "Epoch 30/50\n",
      "100/100 [==============================] - 0s 945us/step - loss: 0.7875 - val_loss: 0.8010\n",
      "Epoch 31/50\n",
      "100/100 [==============================] - 0s 913us/step - loss: 0.7815 - val_loss: 0.7984\n",
      "Epoch 32/50\n",
      "100/100 [==============================] - 0s 904us/step - loss: 0.7769 - val_loss: 0.7901\n",
      "Epoch 33/50\n",
      "100/100 [==============================] - 0s 890us/step - loss: 0.7733 - val_loss: 0.7856\n",
      "Epoch 34/50\n",
      "100/100 [==============================] - 0s 900us/step - loss: 0.7696 - val_loss: 0.7810\n",
      "Epoch 35/50\n",
      "100/100 [==============================] - 0s 909us/step - loss: 0.7635 - val_loss: 0.7794\n",
      "Epoch 36/50\n",
      "100/100 [==============================] - 0s 930us/step - loss: 0.7606 - val_loss: 0.7776\n",
      "Epoch 37/50\n",
      "100/100 [==============================] - 0s 911us/step - loss: 0.7568 - val_loss: 0.7700\n",
      "Epoch 38/50\n",
      "100/100 [==============================] - 0s 903us/step - loss: 0.7525 - val_loss: 0.7795\n",
      "Epoch 39/50\n",
      "100/100 [==============================] - 0s 924us/step - loss: 0.7496 - val_loss: 0.7650\n",
      "Epoch 40/50\n",
      "100/100 [==============================] - 0s 899us/step - loss: 0.7455 - val_loss: 0.7621\n",
      "Epoch 41/50\n",
      "100/100 [==============================] - 0s 903us/step - loss: 0.7421 - val_loss: 0.7595\n",
      "Epoch 42/50\n",
      "100/100 [==============================] - 0s 914us/step - loss: 0.7379 - val_loss: 0.7575\n",
      "Epoch 43/50\n",
      "100/100 [==============================] - 0s 912us/step - loss: 0.7367 - val_loss: 0.7509\n",
      "Epoch 44/50\n",
      "100/100 [==============================] - 0s 900us/step - loss: 0.7335 - val_loss: 0.7484\n",
      "Epoch 45/50\n",
      "100/100 [==============================] - 0s 931us/step - loss: 0.7304 - val_loss: 0.7453\n",
      "Epoch 46/50\n",
      "100/100 [==============================] - 0s 924us/step - loss: 0.7282 - val_loss: 0.7435\n",
      "Epoch 47/50\n",
      "100/100 [==============================] - 0s 914us/step - loss: 0.7274 - val_loss: 0.7430\n",
      "Epoch 48/50\n",
      "100/100 [==============================] - 0s 945us/step - loss: 0.7239 - val_loss: 0.7389\n",
      "Epoch 49/50\n",
      "100/100 [==============================] - 0s 914us/step - loss: 0.7233 - val_loss: 0.7377\n",
      "Epoch 50/50\n",
      "100/100 [==============================] - 0s 939us/step - loss: 0.7194 - val_loss: 0.7365\n",
      "100/100 [==============================] - 0s 495us/step\n",
      "25/25 [==============================] - 0s 500us/step\n",
      "0.25249999999999995\n",
      "The presence of material_advantage in resblock 0 is 0.1775\n",
      "(4000, 320)\n",
      "Performing regression for layer 1\n",
      "Epoch 1/50\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.9772 - val_loss: 0.9598\n",
      "Epoch 2/50\n",
      "100/100 [==============================] - 0s 874us/step - loss: 0.9411 - val_loss: 0.9342\n",
      "Epoch 3/50\n",
      "100/100 [==============================] - 0s 880us/step - loss: 0.9166 - val_loss: 0.9139\n",
      "Epoch 4/50\n",
      "100/100 [==============================] - 0s 879us/step - loss: 0.8975 - val_loss: 0.8979\n",
      "Epoch 5/50\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.8814 - val_loss: 0.8841\n",
      "Epoch 6/50\n",
      "100/100 [==============================] - 0s 921us/step - loss: 0.8683 - val_loss: 0.8721\n",
      "Epoch 7/50\n",
      "100/100 [==============================] - 0s 909us/step - loss: 0.8557 - val_loss: 0.8618\n",
      "Epoch 8/50\n",
      "100/100 [==============================] - 0s 971us/step - loss: 0.8449 - val_loss: 0.8519\n",
      "Epoch 9/50\n",
      "100/100 [==============================] - 0s 922us/step - loss: 0.8346 - val_loss: 0.8423\n",
      "Epoch 10/50\n",
      "100/100 [==============================] - 0s 891us/step - loss: 0.8252 - val_loss: 0.8333\n",
      "Epoch 11/50\n",
      "100/100 [==============================] - 0s 914us/step - loss: 0.8168 - val_loss: 0.8258\n",
      "Epoch 12/50\n",
      "100/100 [==============================] - 0s 894us/step - loss: 0.8089 - val_loss: 0.8181\n",
      "Epoch 13/50\n",
      "100/100 [==============================] - 0s 869us/step - loss: 0.8016 - val_loss: 0.8119\n",
      "Epoch 14/50\n",
      "100/100 [==============================] - 0s 882us/step - loss: 0.7951 - val_loss: 0.8048\n",
      "Epoch 15/50\n",
      "100/100 [==============================] - 0s 904us/step - loss: 0.7885 - val_loss: 0.7984\n",
      "Epoch 16/50\n",
      "100/100 [==============================] - 0s 914us/step - loss: 0.7819 - val_loss: 0.7930\n",
      "Epoch 17/50\n",
      "100/100 [==============================] - 0s 894us/step - loss: 0.7759 - val_loss: 0.7863\n",
      "Epoch 18/50\n",
      "100/100 [==============================] - 0s 868us/step - loss: 0.7702 - val_loss: 0.7810\n",
      "Epoch 19/50\n",
      "100/100 [==============================] - 0s 892us/step - loss: 0.7644 - val_loss: 0.7754\n",
      "Epoch 20/50\n",
      "100/100 [==============================] - 0s 903us/step - loss: 0.7591 - val_loss: 0.7703\n",
      "Epoch 21/50\n",
      "100/100 [==============================] - 0s 904us/step - loss: 0.7540 - val_loss: 0.7646\n",
      "Epoch 22/50\n",
      "100/100 [==============================] - 0s 911us/step - loss: 0.7489 - val_loss: 0.7600\n",
      "Epoch 23/50\n",
      "100/100 [==============================] - 0s 890us/step - loss: 0.7446 - val_loss: 0.7560\n",
      "Epoch 24/50\n",
      "100/100 [==============================] - 0s 884us/step - loss: 0.7403 - val_loss: 0.7519\n",
      "Epoch 25/50\n",
      "100/100 [==============================] - 0s 884us/step - loss: 0.7362 - val_loss: 0.7485\n",
      "Epoch 26/50\n",
      "100/100 [==============================] - 0s 870us/step - loss: 0.7327 - val_loss: 0.7443\n",
      "Epoch 27/50\n",
      "100/100 [==============================] - 0s 869us/step - loss: 0.7292 - val_loss: 0.7414\n",
      "Epoch 28/50\n",
      "100/100 [==============================] - 0s 879us/step - loss: 0.7261 - val_loss: 0.7380\n",
      "Epoch 29/50\n",
      "100/100 [==============================] - 0s 889us/step - loss: 0.7233 - val_loss: 0.7349\n",
      "Epoch 30/50\n",
      "100/100 [==============================] - 0s 884us/step - loss: 0.7203 - val_loss: 0.7323\n",
      "Epoch 31/50\n",
      "100/100 [==============================] - 0s 882us/step - loss: 0.7178 - val_loss: 0.7300\n",
      "Epoch 32/50\n",
      "100/100 [==============================] - 0s 874us/step - loss: 0.7154 - val_loss: 0.7274\n",
      "Epoch 33/50\n",
      "100/100 [==============================] - 0s 879us/step - loss: 0.7132 - val_loss: 0.7249\n",
      "Epoch 34/50\n",
      "100/100 [==============================] - 0s 873us/step - loss: 0.7109 - val_loss: 0.7240\n",
      "Epoch 35/50\n",
      "100/100 [==============================] - 0s 874us/step - loss: 0.7089 - val_loss: 0.7207\n",
      "Epoch 36/50\n",
      "100/100 [==============================] - 0s 861us/step - loss: 0.7071 - val_loss: 0.7190\n",
      "Epoch 37/50\n",
      "100/100 [==============================] - 0s 891us/step - loss: 0.7054 - val_loss: 0.7171\n",
      "Epoch 38/50\n",
      "100/100 [==============================] - 0s 869us/step - loss: 0.7037 - val_loss: 0.7153\n",
      "Epoch 39/50\n",
      "100/100 [==============================] - 0s 882us/step - loss: 0.7022 - val_loss: 0.7140\n",
      "Epoch 40/50\n",
      "100/100 [==============================] - 0s 884us/step - loss: 0.7007 - val_loss: 0.7136\n",
      "Epoch 41/50\n",
      "100/100 [==============================] - 0s 873us/step - loss: 0.6995 - val_loss: 0.7107\n",
      "Epoch 42/50\n",
      "100/100 [==============================] - 0s 874us/step - loss: 0.6981 - val_loss: 0.7094\n",
      "Epoch 43/50\n",
      "100/100 [==============================] - 0s 880us/step - loss: 0.6968 - val_loss: 0.7082\n",
      "Epoch 44/50\n",
      "100/100 [==============================] - 0s 872us/step - loss: 0.6955 - val_loss: 0.7065\n",
      "Epoch 45/50\n",
      "100/100 [==============================] - 0s 935us/step - loss: 0.6943 - val_loss: 0.7054\n",
      "Epoch 46/50\n",
      "100/100 [==============================] - 0s 904us/step - loss: 0.6933 - val_loss: 0.7055\n",
      "Epoch 47/50\n",
      "100/100 [==============================] - 0s 914us/step - loss: 0.6922 - val_loss: 0.7032\n",
      "Epoch 48/50\n",
      "100/100 [==============================] - 0s 890us/step - loss: 0.6912 - val_loss: 0.7023\n",
      "Epoch 49/50\n",
      "100/100 [==============================] - 0s 889us/step - loss: 0.6904 - val_loss: 0.7007\n",
      "Epoch 50/50\n",
      "100/100 [==============================] - 0s 873us/step - loss: 0.6893 - val_loss: 0.6998\n",
      "100/100 [==============================] - 0s 485us/step\n",
      "25/25 [==============================] - 0s 500us/step\n",
      "0.264375\n",
      "The presence of material_advantage in resblock 1 is 0.2649999999999999\n",
      "Getting outputs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 125/125 [00:01<00:00, 96.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merging outputs...\n",
      "Outputs merged.\n",
      "(4000, 980)\n",
      "Performing regression for layer 0\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 0s 2ms/step - loss: 1.1452 - val_loss: 1.1197\n",
      "Epoch 2/50\n",
      "100/100 [==============================] - 0s 956us/step - loss: 1.1086 - val_loss: 1.0935\n",
      "Epoch 3/50\n",
      "100/100 [==============================] - 0s 915us/step - loss: 1.0832 - val_loss: 1.0713\n",
      "Epoch 4/50\n",
      "100/100 [==============================] - 0s 924us/step - loss: 1.0611 - val_loss: 1.0579\n",
      "Epoch 5/50\n",
      "100/100 [==============================] - 0s 915us/step - loss: 1.0478 - val_loss: 1.0358\n",
      "Epoch 6/50\n",
      "100/100 [==============================] - 0s 918us/step - loss: 1.0261 - val_loss: 1.0225\n",
      "Epoch 7/50\n",
      "100/100 [==============================] - 0s 922us/step - loss: 1.0128 - val_loss: 1.0086\n",
      "Epoch 8/50\n",
      "100/100 [==============================] - 0s 905us/step - loss: 0.9996 - val_loss: 0.9976\n",
      "Epoch 9/50\n",
      "100/100 [==============================] - 0s 919us/step - loss: 0.9866 - val_loss: 0.9857\n",
      "Epoch 10/50\n",
      "100/100 [==============================] - 0s 945us/step - loss: 0.9739 - val_loss: 0.9728\n",
      "Epoch 11/50\n",
      "100/100 [==============================] - 0s 887us/step - loss: 0.9624 - val_loss: 0.9621\n",
      "Epoch 12/50\n",
      "100/100 [==============================] - 0s 897us/step - loss: 0.9528 - val_loss: 0.9545\n",
      "Epoch 13/50\n",
      "100/100 [==============================] - 0s 899us/step - loss: 0.9433 - val_loss: 0.9417\n",
      "Epoch 14/50\n",
      "100/100 [==============================] - 0s 904us/step - loss: 0.9332 - val_loss: 0.9334\n",
      "Epoch 15/50\n",
      "100/100 [==============================] - 0s 913us/step - loss: 0.9238 - val_loss: 0.9228\n",
      "Epoch 16/50\n",
      "100/100 [==============================] - 0s 897us/step - loss: 0.9126 - val_loss: 0.9154\n",
      "Epoch 17/50\n",
      "100/100 [==============================] - 0s 901us/step - loss: 0.9026 - val_loss: 0.9045\n",
      "Epoch 18/50\n",
      "100/100 [==============================] - 0s 939us/step - loss: 0.8949 - val_loss: 0.8968\n",
      "Epoch 19/50\n",
      "100/100 [==============================] - 0s 925us/step - loss: 0.8870 - val_loss: 0.8925\n",
      "Epoch 20/50\n",
      "100/100 [==============================] - 0s 902us/step - loss: 0.8768 - val_loss: 0.8806\n",
      "Epoch 21/50\n",
      "100/100 [==============================] - 0s 936us/step - loss: 0.8697 - val_loss: 0.8731\n",
      "Epoch 22/50\n",
      "100/100 [==============================] - 0s 911us/step - loss: 0.8607 - val_loss: 0.8646\n",
      "Epoch 23/50\n",
      "100/100 [==============================] - 0s 914us/step - loss: 0.8536 - val_loss: 0.8593\n",
      "Epoch 24/50\n",
      "100/100 [==============================] - 0s 944us/step - loss: 0.8460 - val_loss: 0.8501\n",
      "Epoch 25/50\n",
      "100/100 [==============================] - 0s 951us/step - loss: 0.8393 - val_loss: 0.8434\n",
      "Epoch 26/50\n",
      "100/100 [==============================] - 0s 936us/step - loss: 0.8326 - val_loss: 0.8371\n",
      "Epoch 27/50\n",
      "100/100 [==============================] - 0s 933us/step - loss: 0.8257 - val_loss: 0.8321\n",
      "Epoch 28/50\n",
      "100/100 [==============================] - 0s 919us/step - loss: 0.8192 - val_loss: 0.8236\n",
      "Epoch 29/50\n",
      "100/100 [==============================] - 0s 898us/step - loss: 0.8130 - val_loss: 0.8212\n",
      "Epoch 30/50\n",
      "100/100 [==============================] - 0s 907us/step - loss: 0.8071 - val_loss: 0.8145\n",
      "Epoch 31/50\n",
      "100/100 [==============================] - 0s 945us/step - loss: 0.8007 - val_loss: 0.8065\n",
      "Epoch 32/50\n",
      "100/100 [==============================] - 0s 932us/step - loss: 0.7964 - val_loss: 0.8022\n",
      "Epoch 33/50\n",
      "100/100 [==============================] - 0s 904us/step - loss: 0.7913 - val_loss: 0.7962\n",
      "Epoch 34/50\n",
      "100/100 [==============================] - 0s 904us/step - loss: 0.7848 - val_loss: 0.7936\n",
      "Epoch 35/50\n",
      "100/100 [==============================] - 0s 903us/step - loss: 0.7797 - val_loss: 0.7862\n",
      "Epoch 36/50\n",
      "100/100 [==============================] - 0s 919us/step - loss: 0.7741 - val_loss: 0.7803\n",
      "Epoch 37/50\n",
      "100/100 [==============================] - 0s 984us/step - loss: 0.7696 - val_loss: 0.7781\n",
      "Epoch 38/50\n",
      "100/100 [==============================] - 0s 957us/step - loss: 0.7644 - val_loss: 0.7710\n",
      "Epoch 39/50\n",
      "100/100 [==============================] - 0s 922us/step - loss: 0.7607 - val_loss: 0.7662\n",
      "Epoch 40/50\n",
      "100/100 [==============================] - 0s 890us/step - loss: 0.7563 - val_loss: 0.7634\n",
      "Epoch 41/50\n",
      "100/100 [==============================] - 0s 892us/step - loss: 0.7538 - val_loss: 0.7589\n",
      "Epoch 42/50\n",
      "100/100 [==============================] - 0s 924us/step - loss: 0.7485 - val_loss: 0.7548\n",
      "Epoch 43/50\n",
      "100/100 [==============================] - 0s 943us/step - loss: 0.7442 - val_loss: 0.7643\n",
      "Epoch 44/50\n",
      "100/100 [==============================] - 0s 923us/step - loss: 0.7438 - val_loss: 0.7481\n",
      "Epoch 45/50\n",
      "100/100 [==============================] - 0s 921us/step - loss: 0.7375 - val_loss: 0.7457\n",
      "Epoch 46/50\n",
      "100/100 [==============================] - 0s 949us/step - loss: 0.7359 - val_loss: 0.7413\n",
      "Epoch 47/50\n",
      "100/100 [==============================] - 0s 939us/step - loss: 0.7320 - val_loss: 0.7408\n",
      "Epoch 48/50\n",
      "100/100 [==============================] - 0s 964us/step - loss: 0.7312 - val_loss: 0.7363\n",
      "Epoch 49/50\n",
      "100/100 [==============================] - 0s 914us/step - loss: 0.7273 - val_loss: 0.7438\n",
      "Epoch 50/50\n",
      "100/100 [==============================] - 0s 906us/step - loss: 0.7243 - val_loss: 0.7317\n",
      "100/100 [==============================] - 0s 523us/step\n",
      "25/25 [==============================] - 0s 549us/step\n",
      "0.25312500000000004\n",
      "The presence of material_advantage in resblock 0 is 0.21500000000000008\n",
      "(4000, 320)\n",
      "Performing regression for layer 1\n",
      "Epoch 1/50\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.9564 - val_loss: 0.9407\n",
      "Epoch 2/50\n",
      "100/100 [==============================] - 0s 926us/step - loss: 0.9155 - val_loss: 0.9180\n",
      "Epoch 3/50\n",
      "100/100 [==============================] - 0s 885us/step - loss: 0.8971 - val_loss: 0.9011\n",
      "Epoch 4/50\n",
      "100/100 [==============================] - 0s 905us/step - loss: 0.8823 - val_loss: 0.8869\n",
      "Epoch 5/50\n",
      "100/100 [==============================] - 0s 912us/step - loss: 0.8692 - val_loss: 0.8741\n",
      "Epoch 6/50\n",
      "100/100 [==============================] - 0s 977us/step - loss: 0.8578 - val_loss: 0.8632\n",
      "Epoch 7/50\n",
      "100/100 [==============================] - 0s 913us/step - loss: 0.8474 - val_loss: 0.8529\n",
      "Epoch 8/50\n",
      "100/100 [==============================] - 0s 891us/step - loss: 0.8376 - val_loss: 0.8440\n",
      "Epoch 9/50\n",
      "100/100 [==============================] - 0s 883us/step - loss: 0.8289 - val_loss: 0.8356\n",
      "Epoch 10/50\n",
      "100/100 [==============================] - 0s 902us/step - loss: 0.8207 - val_loss: 0.8274\n",
      "Epoch 11/50\n",
      "100/100 [==============================] - 0s 903us/step - loss: 0.8123 - val_loss: 0.8202\n",
      "Epoch 12/50\n",
      "100/100 [==============================] - 0s 905us/step - loss: 0.8049 - val_loss: 0.8124\n",
      "Epoch 13/50\n",
      "100/100 [==============================] - 0s 967us/step - loss: 0.7975 - val_loss: 0.8051\n",
      "Epoch 14/50\n",
      "100/100 [==============================] - 0s 915us/step - loss: 0.7905 - val_loss: 0.7988\n",
      "Epoch 15/50\n",
      "100/100 [==============================] - 0s 925us/step - loss: 0.7839 - val_loss: 0.7920\n",
      "Epoch 16/50\n",
      "100/100 [==============================] - 0s 913us/step - loss: 0.7777 - val_loss: 0.7861\n",
      "Epoch 17/50\n",
      "100/100 [==============================] - 0s 934us/step - loss: 0.7719 - val_loss: 0.7803\n",
      "Epoch 18/50\n",
      "100/100 [==============================] - 0s 886us/step - loss: 0.7664 - val_loss: 0.7750\n",
      "Epoch 19/50\n",
      "100/100 [==============================] - 0s 901us/step - loss: 0.7612 - val_loss: 0.7697\n",
      "Epoch 20/50\n",
      "100/100 [==============================] - 0s 931us/step - loss: 0.7561 - val_loss: 0.7652\n",
      "Epoch 21/50\n",
      "100/100 [==============================] - 0s 905us/step - loss: 0.7518 - val_loss: 0.7604\n",
      "Epoch 22/50\n",
      "100/100 [==============================] - 0s 873us/step - loss: 0.7474 - val_loss: 0.7560\n",
      "Epoch 23/50\n",
      "100/100 [==============================] - 0s 865us/step - loss: 0.7433 - val_loss: 0.7519\n",
      "Epoch 24/50\n",
      "100/100 [==============================] - 0s 898us/step - loss: 0.7390 - val_loss: 0.7481\n",
      "Epoch 25/50\n",
      "100/100 [==============================] - 0s 895us/step - loss: 0.7353 - val_loss: 0.7441\n",
      "Epoch 26/50\n",
      "100/100 [==============================] - 0s 922us/step - loss: 0.7317 - val_loss: 0.7408\n",
      "Epoch 27/50\n",
      "100/100 [==============================] - 0s 906us/step - loss: 0.7283 - val_loss: 0.7373\n",
      "Epoch 28/50\n",
      "100/100 [==============================] - 0s 888us/step - loss: 0.7250 - val_loss: 0.7345\n",
      "Epoch 29/50\n",
      "100/100 [==============================] - 0s 911us/step - loss: 0.7219 - val_loss: 0.7309\n",
      "Epoch 30/50\n",
      "100/100 [==============================] - 0s 881us/step - loss: 0.7188 - val_loss: 0.7282\n",
      "Epoch 31/50\n",
      "100/100 [==============================] - 0s 950us/step - loss: 0.7161 - val_loss: 0.7253\n",
      "Epoch 32/50\n",
      "100/100 [==============================] - 0s 956us/step - loss: 0.7135 - val_loss: 0.7227\n",
      "Epoch 33/50\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.7111 - val_loss: 0.7204\n",
      "Epoch 34/50\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.7087 - val_loss: 0.7181\n",
      "Epoch 35/50\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.7065 - val_loss: 0.7157\n",
      "Epoch 36/50\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.7047 - val_loss: 0.7140\n",
      "Epoch 37/50\n",
      "100/100 [==============================] - 0s 936us/step - loss: 0.7027 - val_loss: 0.7119\n",
      "Epoch 38/50\n",
      "100/100 [==============================] - 0s 873us/step - loss: 0.7009 - val_loss: 0.7105\n",
      "Epoch 39/50\n",
      "100/100 [==============================] - 0s 869us/step - loss: 0.6993 - val_loss: 0.7088\n",
      "Epoch 40/50\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6975 - val_loss: 0.7068\n",
      "Epoch 41/50\n",
      "100/100 [==============================] - 0s 990us/step - loss: 0.6960 - val_loss: 0.7053\n",
      "Epoch 42/50\n",
      "100/100 [==============================] - 0s 886us/step - loss: 0.6948 - val_loss: 0.7036\n",
      "Epoch 43/50\n",
      "100/100 [==============================] - 0s 977us/step - loss: 0.6934 - val_loss: 0.7022\n",
      "Epoch 44/50\n",
      "100/100 [==============================] - 0s 985us/step - loss: 0.6920 - val_loss: 0.7006\n",
      "Epoch 45/50\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6906 - val_loss: 0.6994\n",
      "Epoch 46/50\n",
      "100/100 [==============================] - 0s 944us/step - loss: 0.6896 - val_loss: 0.6981\n",
      "Epoch 47/50\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6885 - val_loss: 0.6970\n",
      "Epoch 48/50\n",
      "100/100 [==============================] - 0s 964us/step - loss: 0.6874 - val_loss: 0.6958\n",
      "Epoch 49/50\n",
      "100/100 [==============================] - 0s 961us/step - loss: 0.6864 - val_loss: 0.6947\n",
      "Epoch 50/50\n",
      "100/100 [==============================] - 0s 961us/step - loss: 0.6853 - val_loss: 0.6937\n",
      "100/100 [==============================] - 0s 477us/step\n",
      "25/25 [==============================] - 0s 539us/step\n",
      "0.2562500000000001\n",
      "The presence of material_advantage in resblock 1 is 0.25249999999999995\n"
     ]
    }
   ],
   "source": [
    "from minichess.agents.convnet import ConvNet\n",
    "\n",
    "for epoch_to_look_at in epochs_to_look_at:\n",
    "    import tensorflow.keras as keras\n",
    "    predictor_model = ConvNet(None, None, init=False)\n",
    "    predictor_model.model = keras.models.load_model(\"minichess/agents/checkpoints/{}/{}/{}\".format(full_name, model_name, epoch_to_look_at))\n",
    "    all_cases = np.concatenate([positive_cases, negative_cases])\n",
    "    all_labels = [1] * positive_cases.shape[0] + [0] * negative_cases.shape[0]\n",
    "    all_labels = np.array(all_labels)\n",
    "    shuffled_indices = np.arange(all_labels.shape[0])\n",
    "    np.random.shuffle(shuffled_indices)\n",
    "    all_cases = all_cases[shuffled_indices]\n",
    "    all_labels = all_labels[shuffled_indices]\n",
    "    POSITIONS_TO_CONSIDER = 3200\n",
    "    VALIDATION_POSITIONS = 800\n",
    "    from minichess.concepts.linear_regression import perform_linear_regression, perform_logistic_regression, perform_regression\n",
    "\n",
    "    concept_presences = {}\n",
    "\n",
    "\n",
    "    print(\"Getting outputs...\")\n",
    "    outputs = predictor_model.get_all_resblock_outputs(all_cases)\n",
    "    # actual_outputs = predictor_model.predict(boards, id_vector_to_use)\n",
    "    # Outputs blir returnert i batcher, må flette det sammen\n",
    "    print(\"Merging outputs...\")\n",
    "    merged_outputs = []\n",
    "    for output_batch in outputs:\n",
    "        for i, output_layer in enumerate(output_batch):\n",
    "            if len(merged_outputs) <= i:\n",
    "                merged_outputs.append([])\n",
    "            merged_outputs[i].extend(output_layer)\n",
    "\n",
    "    for i, layer_output in enumerate(merged_outputs):\n",
    "        merged_outputs[i] = np.array(merged_outputs[i])\n",
    "    outputs = merged_outputs\n",
    "    print(\"Outputs merged.\")\n",
    "    # Aktiveringer fra res-block i\n",
    "    concept_presence_per_layer = []\n",
    "    for (i, output) in enumerate(outputs):\n",
    "        points = output.reshape((output.shape[0], np.prod(output.shape[1:])))\n",
    "        print(points.shape)\n",
    "        # Så man har (n, k) sampler der n er antallet posisjoner, og k er det totale antallet aktiveringsverdier i lag i.\n",
    "        print(\"Performing regression for layer {}\".format(i))\n",
    "        # points = np.concatenate([points, actual_outputs], axis=1)\n",
    "        score = perform_regression(\n",
    "            points[:POSITIONS_TO_CONSIDER],\n",
    "            all_labels[:POSITIONS_TO_CONSIDER],\n",
    "            points[POSITIONS_TO_CONSIDER:],\n",
    "            all_labels[POSITIONS_TO_CONSIDER:],\n",
    "            True\n",
    "        )\n",
    "        concept_presence_per_layer.append(score)\n",
    "\n",
    "        print(\"The presence of {} in resblock {} is {}\".format(concept_name, i, score))\n",
    "    concept_presences[concept_name] = concept_presence_per_layer\n",
    "    import os\n",
    "    import string\n",
    "    from random import choices\n",
    "    import json\n",
    "\n",
    "    os.makedirs(\"concept_presences\", exist_ok=True)\n",
    "    os.makedirs(\"concept_presences/{}\".format(full_name), exist_ok=True)\n",
    "    os.makedirs(\"concept_presences/{}/{}\".format(full_name, model_name), exist_ok=True)\n",
    "    os.makedirs(\"concept_presences/{}/{}/{}\".format(full_name, model_name, concept_name), exist_ok=True)\n",
    "    os.makedirs(\"concept_presences/{}/{}/{}/{}\".format(full_name, model_name, concept_name, epoch_to_look_at), exist_ok=True)\n",
    "\n",
    "    random_suffix = ''.join(choices(string.ascii_uppercase + string.digits, k=10))\n",
    "\n",
    "    with open(\"concept_presences/{}/{}/{}/{}/{}.json\".format(full_name, model_name, concept_name, epoch_to_look_at, random_suffix), \"w\") as f:\n",
    "        json.dump(concept_presences[concept_name], f)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
